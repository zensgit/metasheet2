name: Attendance Import Perf Long Run

# Mark drill runs explicitly so dashboards can ignore them.
run-name: Attendance Import Perf Long Run${{ github.event_name == 'workflow_dispatch' && inputs.drill == 'true' && ' [DRILL]' || '' }}

on:
  workflow_dispatch:
    inputs:
      drill:
        description: 'Optional: mark run as [DRILL] and skip calling production APIs (true/false)'
        required: false
        default: 'false'
      drill_fail:
        description: 'Optional: intentionally fail the drill job for FAIL-path validation (true/false)'
        required: false
        default: 'false'
      issue_title:
        description: 'Optional: override issue title for workflow_dispatch drills (leave empty for production title)'
        required: false
        default: ''
      upload_csv:
        description: 'Upload CSV via /attendance/import/upload (true/false)'
        required: false
        default: 'true'
      include_rows500k_preview:
        description: 'Run rows500k-preview scenario (true/false)'
        required: false
        default: 'true'
      include_rows500k_commit:
        description: 'Run rows500k-commit scenario (true/false)'
        required: false
        default: 'true'
      api_base:
        description: 'API base (must end with /api)'
        required: false
        default: 'http://142.171.239.56:8081/api'
      branch:
        description: 'Branch to analyze for trend history'
        required: false
        default: 'main'
      trend_depth:
        description: 'History depth per scenario for trend report'
        required: false
        default: '7'
      history_download_limit:
        description: 'How many previous runs to download for trend history'
        required: false
        default: '5'
      fail_on_regression:
        description: 'Fail trend job when drift/regression warning exists (true/false)'
        required: false
        default: 'false'
  schedule:
    # Daily at 05:10 UTC.
    - cron: '10 5 * * *'

concurrency:
  group: attendance-import-perf-longrun
  cancel-in-progress: true

permissions:
  contents: read
  actions: read
  issues: write

jobs:
  drill:
    if: github.event_name == 'workflow_dispatch' && inputs.drill == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 5
    env:
      DRILL_FAIL: ${{ inputs.drill_fail || 'false' }}
    steps:
      - name: Drill no-op (skip long run)
        run: |
          set -euo pipefail
          DRILL_FAIL="${DRILL_FAIL:-false}"
          mkdir -p output/playwright/attendance-import-perf-longrun/drill
          cat > output/playwright/attendance-import-perf-longrun/drill/drill.txt <<'EOF'
          This is a DRILL run for Attendance Import Perf Long Run.
          The workflow intentionally skips calling production APIs.
          EOF

          # Provide a minimal scenario summary so dashboards can exercise
          # artifact parsing without calling production.
          mkdir -p output/playwright/attendance-import-perf-longrun/drill/current-flat
          cat > output/playwright/attendance-import-perf-longrun/drill/current-flat/rows10000-commit.json <<'EOF'
          {
            "startedAt": "1970-01-01T00:00:00.000Z",
            "scenario": "rows10k-commit",
            "mode": "commit",
            "apiBase": "<DRILL>",
            "orgId": "default",
            "rows": 10000,
            "commitAsync": true,
            "uploadCsv": true,
            "previewMs": 4444,
            "commitMs": 5555,
            "exportMs": 666,
            "rollbackMs": 77,
            "thresholds": {
              "maxPreviewMs": 100000,
              "maxCommitMs": 150000,
              "maxExportMs": 25000,
              "maxRollbackMs": 8000
            },
            "regressions": [
              "DRILL: synthetic longrun regression entry"
            ]
          }
          EOF

          if [[ "$DRILL_FAIL" == "true" ]]; then
            echo "DRILL_FAIL=true: intentional failure after creating drill artifacts" >&2
            exit 97
          fi

      - name: Upload drill artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: attendance-import-perf-longrun-drill-${{ github.run_id }}-${{ github.run_attempt }}
          retention-days: 14
          path: |
            output/playwright/attendance-import-perf-longrun/drill/**

  perf-scenarios:
    if: github.event_name != 'workflow_dispatch' || inputs.drill != 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 50
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        include:
          - id: rows10k-commit
            rows: '10000'
            mode: 'commit'
            commit_async: 'false'
            export_csv: 'true'
            rollback: 'false'
            expected_upsert_strategy: ''
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_10K_MAX_PREVIEW_MS || vars.ATTENDANCE_PERF_MAX_PREVIEW_MS || '100000' }}
            max_commit_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_10K_MAX_COMMIT_MS || vars.ATTENDANCE_PERF_MAX_COMMIT_MS || '150000' }}
            max_export_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_10K_MAX_EXPORT_MS || vars.ATTENDANCE_PERF_MAX_EXPORT_MS || '25000' }}
            max_rollback_ms: ''
          - id: rows100k-commit
            rows: '100000'
            mode: 'commit'
            commit_async: 'false'
            export_csv: 'true'
            rollback: 'false'
            expected_upsert_strategy: 'staging'
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_100K_COMMIT_MAX_PREVIEW_MS || '180000' }}
            max_commit_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_100K_COMMIT_MAX_COMMIT_MS || '300000' }}
            max_export_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_100K_COMMIT_MAX_EXPORT_MS || '45000' }}
            max_rollback_ms: ''
          - id: rows50k-preview
            rows: '50000'
            mode: 'preview'
            commit_async: 'true'
            export_csv: 'false'
            rollback: 'false'
            expected_upsert_strategy: ''
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_50K_MAX_PREVIEW_MS || '180000' }}
            max_commit_ms: ''
            max_export_ms: ''
            max_rollback_ms: ''
          - id: rows100k-preview
            rows: '100000'
            mode: 'preview'
            commit_async: 'true'
            export_csv: 'false'
            rollback: 'false'
            expected_upsert_strategy: ''
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_100K_MAX_PREVIEW_MS || '240000' }}
            max_commit_ms: ''
            max_export_ms: ''
            max_rollback_ms: ''
          - id: rows500k-preview
            rows: '500000'
            mode: 'preview'
            commit_async: 'true'
            export_csv: 'false'
            rollback: 'false'
            expected_upsert_strategy: ''
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_500K_MAX_PREVIEW_MS || '480000' }}
            max_commit_ms: ''
            max_export_ms: ''
            max_rollback_ms: ''
          - id: rows500k-commit
            rows: '500000'
            mode: 'commit'
            commit_async: 'true'
            export_csv: 'false'
            rollback: 'false'
            expected_upsert_strategy: 'staging'
            max_preview_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_500K_COMMIT_MAX_PREVIEW_MS || '600000' }}
            max_commit_ms: ${{ vars.ATTENDANCE_PERF_LONGRUN_500K_COMMIT_MAX_COMMIT_MS || '900000' }}
            max_export_ms: ''
            max_rollback_ms: ''
    env:
      API_BASE: ${{ inputs.api_base || vars.ATTENDANCE_API_BASE || 'http://142.171.239.56:8081/api' }}
      AUTH_TOKEN: ${{ secrets.ATTENDANCE_ADMIN_JWT }}
      COMMIT_ASYNC: 'true'
      UPLOAD_CSV: ${{ inputs.upload_csv || vars.ATTENDANCE_PERF_UPLOAD_CSV || 'true' }}
      INCLUDE_ROWS500K_PREVIEW: ${{ inputs.include_rows500k_preview || vars.ATTENDANCE_PERF_LONGRUN_INCLUDE_500K_PREVIEW || 'true' }}
      INCLUDE_ROWS500K_COMMIT: ${{ inputs.include_rows500k_commit || vars.ATTENDANCE_PERF_LONGRUN_INCLUDE_500K_COMMIT || 'true' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Run long-run scenario
        if: >
          (matrix.id != 'rows500k-preview' || env.INCLUDE_ROWS500K_PREVIEW == 'true')
          && (matrix.id != 'rows500k-commit' || env.INCLUDE_ROWS500K_COMMIT == 'true')
        env:
          SCENARIO: ${{ matrix.id }}
          ROWS: ${{ matrix.rows }}
          MODE: ${{ matrix.mode }}
          COMMIT_ASYNC: ${{ matrix.commit_async }}
          EXPORT_CSV: ${{ matrix.export_csv }}
          ROLLBACK: ${{ matrix.rollback }}
          MAX_PREVIEW_MS: ${{ matrix.max_preview_ms }}
          MAX_COMMIT_MS: ${{ matrix.max_commit_ms }}
          MAX_EXPORT_MS: ${{ matrix.max_export_ms }}
          MAX_ROLLBACK_MS: ${{ matrix.max_rollback_ms }}
          EXPECT_RECORD_UPSERT_STRATEGY: ${{ matrix.expected_upsert_strategy }}
          OUTPUT_DIR: output/playwright/attendance-import-perf-longrun/current/${{ matrix.id }}
        run: |
          set -euo pipefail
          # Always capture logs so failures are diagnosable from artifacts.
          mkdir -p "$OUTPUT_DIR"
          node ./scripts/ops/attendance-import-perf.mjs 2>&1 | tee "$OUTPUT_DIR/perf.log"

      - name: Mark rows500k-preview as skipped
        if: matrix.id == 'rows500k-preview' && env.INCLUDE_ROWS500K_PREVIEW != 'true'
        run: |
          echo "Skipping rows500k-preview because INCLUDE_ROWS500K_PREVIEW=${INCLUDE_ROWS500K_PREVIEW}" | tee -a "$GITHUB_STEP_SUMMARY"

      - name: Mark rows500k-commit as skipped
        if: matrix.id == 'rows500k-commit' && env.INCLUDE_ROWS500K_COMMIT != 'true'
        run: |
          echo "Skipping rows500k-commit because INCLUDE_ROWS500K_COMMIT=${INCLUDE_ROWS500K_COMMIT}" | tee -a "$GITHUB_STEP_SUMMARY"

      - name: Capture scenario summary
        if: >
          (matrix.id != 'rows500k-preview' || env.INCLUDE_ROWS500K_PREVIEW == 'true')
          && (matrix.id != 'rows500k-commit' || env.INCLUDE_ROWS500K_COMMIT == 'true')
        run: |
          set -euo pipefail
          SCENARIO_DIR="output/playwright/attendance-import-perf-longrun/current/${{ matrix.id }}"
          SUMMARY_PATH="$(find "$SCENARIO_DIR" -name 'perf-summary.json' -type f | sort | tail -n1)"
          if [[ -z "${SUMMARY_PATH}" ]]; then
            echo "Missing perf-summary.json for ${{ matrix.id }}"
            exit 1
          fi
          mkdir -p output/playwright/attendance-import-perf-longrun/current-flat
          cp "$SUMMARY_PATH" "output/playwright/attendance-import-perf-longrun/current-flat/rows${{ matrix.rows }}-${{ matrix.mode }}.json"

      - name: Upload scenario artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: attendance-import-perf-longrun-${{ matrix.id }}-${{ github.run_id }}-${{ github.run_attempt }}
          retention-days: 21
          path: |
            output/playwright/attendance-import-perf-longrun/current/${{ matrix.id }}/**
            output/playwright/attendance-import-perf-longrun/current-flat/rows${{ matrix.rows }}-${{ matrix.mode }}.json
          if-no-files-found: ignore

  trend-report:
    needs: perf-scenarios
    if: (github.event_name != 'workflow_dispatch' || inputs.drill != 'true') && always()
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      report_status: ${{ steps.trend.outputs.report_status || 'pass' }}
      report_attribution: ${{ steps.trend.outputs.report_attribution || '' }}
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      TARGET_BRANCH: ${{ inputs.branch || 'main' }}
      HISTORY_DOWNLOAD_LIMIT: ${{ inputs.history_download_limit || '5' }}
      TREND_DEPTH: ${{ inputs.trend_depth || '7' }}
      FAIL_ON_REGRESSION: ${{ inputs.fail_on_regression || 'false' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Download current run artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: attendance-import-perf-longrun-*-${{ github.run_id }}-${{ github.run_attempt }}
          merge-multiple: true
          path: output/playwright/attendance-import-perf-longrun/current-merged

      - name: Download historical artifacts
        run: |
          set -euo pipefail
          HISTORY_ROOT="output/playwright/attendance-import-perf-longrun/history"
          mkdir -p "$HISTORY_ROOT"

          mapfile -t RUN_IDS < <(
            gh run list \
              --workflow attendance-import-perf-longrun.yml \
              --branch "$TARGET_BRANCH" \
              --limit 20 \
              --json databaseId,status,conclusion \
            | jq -r '.[] | select(.status == "completed") | .databaseId'
          )

          downloaded=0
          for run_id in "${RUN_IDS[@]}"; do
            if [[ "$run_id" == "$GITHUB_RUN_ID" ]]; then
              continue
            fi
            gh run download "$run_id" -D "$HISTORY_ROOT/$run_id" || true
            downloaded=$((downloaded + 1))
            if [[ "$downloaded" -ge "$HISTORY_DOWNLOAD_LIMIT" ]]; then
              break
            fi
          done

          echo "history_downloaded=${downloaded}" >> "$GITHUB_STEP_SUMMARY"

      - name: Generate trend report
        id: trend
        env:
          CURRENT_ROOT: output/playwright/attendance-import-perf-longrun/current-merged
          HISTORY_ROOT: output/playwright/attendance-import-perf-longrun/history
          OUTPUT_DIR: output/playwright/attendance-import-perf-longrun/report
          TREND_DEPTH: ${{ env.TREND_DEPTH }}
          FAIL_ON_REGRESSION: ${{ env.FAIL_ON_REGRESSION }}
          REGRESSION_FACTOR: '1.30'
        run: |
          set -euo pipefail
          node ./scripts/ops/attendance-import-perf-trend-report.mjs

      - name: Add trend markdown to summary
        if: always()
        run: |
          cat "${{ steps.trend.outputs.report_markdown }}" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload trend artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: attendance-import-perf-longrun-trend-${{ github.run_id }}-${{ github.run_attempt }}
          retention-days: 30
          path: |
            output/playwright/attendance-import-perf-longrun/report/**

      - name: Fail on trend regression
        if: steps.trend.outputs.report_status != 'pass'
        run: |
          echo "Perf long-run trend report indicates regression"
          exit 1

  issue:
    name: Perf Longrun Issue Alert (P1)
    needs: [drill, perf-scenarios, trend-report]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    env:
      DRILL: ${{ github.event.inputs.drill || 'false' }}
      DRILL_FAIL: ${{ github.event.inputs.drill_fail || 'false' }}
      ISSUE_TITLE_OVERRIDE: ${{ github.event.inputs.issue_title || '' }}
      DRILL_RESULT: ${{ needs.drill.result }}
      PERF_RESULT: ${{ needs.perf-scenarios.result }}
      TREND_RESULT: ${{ needs.trend-report.result }}
      TREND_ATTRIBUTION: ${{ needs.trend-report.outputs.report_attribution }}
    steps:
      - name: Open/update issue on failure (P1, no paging)
        uses: actions/github-script@v7
        with:
          script: |
            const drill = String(process.env.DRILL || '').trim() === 'true'
            const drillFail = String(process.env.DRILL_FAIL || '').trim() === 'true'
            const drillResult = String(process.env.DRILL_RESULT || '').trim()
            const perfResult = String(process.env.PERF_RESULT || '').trim()
            const trendResult = String(process.env.TREND_RESULT || '').trim()
            const trendAttribution = String(process.env.TREND_ATTRIBUTION || '').trim()
            const titleOverride = String(process.env.ISSUE_TITLE_OVERRIDE || '').trim()

            const defaultTitle = '[Attendance P1] Perf longrun alert'
            const title = titleOverride || defaultTitle

            const allowIssueOps = !drill || Boolean(titleOverride)
            if (!allowIssueOps) {
              core.info('Drill run: skipping issue operations (no override title).')
              return
            }

            const owner = context.repo.owner
            const repo = context.repo.repo
            const runUrl = `${context.serverUrl}/${owner}/${repo}/actions/runs/${context.runId}`

            const isBad = (value) => value && value !== 'success' && value !== 'skipped'
            const failed = drill ? isBad(drillResult) : (isBad(perfResult) || isBad(trendResult))
            const statusLine = `jobs: perf-scenarios=${perfResult || 'unknown'} trend-report=${trendResult || 'unknown'} drill=${drillResult || 'unknown'}${drill && drillFail ? ' (drill_fail=true)' : ''}`

            const body = [
              'Automated perf longrun tracking issue (P1, no paging).',
              '',
              `Run: ${runUrl}`,
              statusLine,
              trendAttribution ? `Attribution: ${trendAttribution}` : null,
              '',
              'Download:',
              '```bash',
              `gh run download ${context.runId} -D \"output/playwright/ga/${context.runId}\"`,
              '```',
            ].join('\\n')

            const q = `repo:${owner}/${repo} type:issue in:title \"${title}\"`
            const search = await github.rest.search.issuesAndPullRequests({
              q,
              sort: 'updated',
              order: 'desc',
              per_page: 20,
            })
            const items = Array.isArray(search.data.items) ? search.data.items : []
            const match = items.find((item) => item && !item.pull_request && item.title === title) || null

            if (failed) {
              if (match) {
                if (match.state !== 'open') {
                  await github.rest.issues.update({
                    owner,
                    repo,
                    issue_number: match.number,
                    state: 'open',
                    body,
                  })
                  core.info(`Reopened issue #${match.number}`)
                } else {
                  await github.rest.issues.createComment({
                    owner,
                    repo,
                    issue_number: match.number,
                    body,
                  })
                  core.info(`Commented on issue #${match.number}`)
                }
                return
              }

              const created = await github.rest.issues.create({
                owner,
                repo,
                title,
                body,
              })
              core.info(`Created issue #${created.data.number}`)
              return
            }

            // Recovery: close an existing open issue when the longrun gate passes.
            if (!match) {
              core.info('No perf longrun issue found; nothing to close.')
              return
            }
            if (match.state !== 'open') {
              core.info(`Perf longrun issue exists but is already closed (#${match.number}).`)
              return
            }

            await github.rest.issues.createComment({
              owner,
              repo,
              issue_number: match.number,
              body: [
                'Perf longrun recovery detected. Closing issue.',
                '',
                `Run: ${runUrl}`,
                statusLine,
              ].join('\\n'),
            })
            await github.rest.issues.update({
              owner,
              repo,
              issue_number: match.number,
              state: 'closed',
            })
            core.info(`Closed issue #${match.number}`)
